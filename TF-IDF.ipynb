{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08589d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocbulary: ['language' 'love' 'mahtab' 'programming' 'python']\n",
      "   language   love  mahtab  programming  python\n",
      "0     0.000  0.000     1.0        0.000   0.000\n",
      "1     0.681  0.000     0.0        0.518   0.518\n",
      "2     0.000  0.681     0.0        0.518   0.518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "docs = [\"My name is Mahtab.\", \"The programming language name is Python.\", \"I love programming in Python.\"]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(\"Vocbulary:\", vectorizer.get_feature_names_out())\n",
    "\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(df.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "441cfb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "dog\n",
      "is\n",
      "a\n",
      "nice\n",
      "ant\n",
      "no\n",
      "Tensorized Document: tensor([0, 1, 2, 3, 4, 1])\n",
      "Tensorized Document: tensor([0, 5, 2, 6, 1])\n",
      "Document Matrix:\n",
      " tensor([[1., 2., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def getDocMatrix():\n",
    "    #documents = [[\"My\", \"name\", \"is\", \"Mahtab\"],[\"The\", \"programming\", \"language\", \"name\", \"is\", \"Python\"],[\"I\", \"love\", \"programming\", \"in\", \"Python\", \"programming\", \"language\"]]\n",
    "    documents = [[\"the\",\"dog\",\"is\",\"a\",\"nice\",\"dog\"],[\"the\",\"ant\",\"is\",\"no\",\"dog\"]]\n",
    "    nrDocs = len(documents)\n",
    "    vocab = []\n",
    "    for doc in documents:\n",
    "        for word in doc:\n",
    "            if word not in vocab:\n",
    "                word = word.lower()\n",
    "                vocab.append(word)\n",
    "    \n",
    "    for word in vocab:\n",
    "        print(word)\n",
    "    \n",
    "    nrWords = len(vocab)\n",
    "    #initialize the document matrix with zeros\n",
    "    docMatrix = torch.zeros((nrDocs, nrWords), dtype=torch.float32)\n",
    "    #print(\"Document Matrix Shape:\", docMatrix)\n",
    "    #create a dictionary to map words to their indices\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    #print(\"Word to Index Mapping:\", word2idx)\n",
    "    for docIdx, doc in enumerate(documents):\n",
    "        #replace words with their indices and transform the list to torch tensor\n",
    "        tensorizedDoc = torch.tensor([word2idx[word.lower()] for word in doc], dtype=torch.long)\n",
    "        print(\"Tensorized Document:\", tensorizedDoc)\n",
    "        #intermediate matrix where each row represents one token in the document\n",
    "        intermediateMatrix = torch.zeros((len(tensorizedDoc), nrWords), dtype=torch.float32)\n",
    "        rows = torch.arange(len(tensorizedDoc))\n",
    "        intermediateMatrix[rows, tensorizedDoc] = 1.0\n",
    "        #print(\"Intermediate Matrix:\\n\", intermediateMatrix)\n",
    "        #sum the intermediate matrix along the rows to get the document vector\n",
    "        docVector = torch.sum(intermediateMatrix, dim=0)\n",
    "       # print(\"Document Vector:\", docVector)\n",
    "        #assign the document vector to the corresponding row in the document matrix\n",
    "        docMatrix[docIdx] = docVector\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Document Matrix:\\n\", docMatrix)\n",
    "    return docMatrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "docMatrix = getDocMatrix()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a703add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies: tensor([2., 3., 2., 1., 1., 1., 1.])\n",
      "Word Counts per Document: tensor([6., 5.])\n",
      "Term Frequency Matrix:\n",
      " tensor([[0.1667, 0.3333, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.2000, 0.2000]])\n",
      "Document Frequencies: tensor([2, 2, 2, 1, 1, 1, 1])\n",
      "Inverse Document Frequencies: tensor([0.6931, 0.6931, 0.6931, 1.0986, 1.0986, 1.0986, 1.0986])\n",
      "TF-IDF Matrix:\n",
      " tensor([[0.1155, 0.2310, 0.1155, 0.1831, 0.1831, 0.0000, 0.0000],\n",
      "        [0.1386, 0.1386, 0.1386, 0.0000, 0.0000, 0.2197, 0.2197]])\n"
     ]
    }
   ],
   "source": [
    "wordFreq = torch.sum(docMatrix, dim=0)\n",
    "print(\"Word Frequencies:\", wordFreq)\n",
    "wordCount = torch.sum(docMatrix, dim=1)\n",
    "print(\"Word Counts per Document:\", wordCount)\n",
    "\n",
    "termFreqMatrix = torch.div(docMatrix.T, wordCount).T\n",
    "print(\"Term Frequency Matrix:\\n\", termFreqMatrix)\n",
    "\n",
    "docFreq = torch.count_nonzero(docMatrix, dim=0)\n",
    "print(\"Document Frequencies:\", docFreq)\n",
    "\n",
    "inverseDocFreq = torch.log((torch.tensor(docMatrix.size(0), dtype=torch.float32) / (docFreq ))+ 1)\n",
    "print(\"Inverse Document Frequencies:\", inverseDocFreq)\n",
    "\n",
    "tfidfMatrix = termFreqMatrix * inverseDocFreq\n",
    "print(\"TF-IDF Matrix:\\n\", tfidfMatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
